{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cover Type Prediction: Feature Engineering\n",
    "\n",
    "SÃ©bastien meyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import MT19937, RandomState, SeedSequence\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy as hc\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, LabelBinarizer, StandardScaler\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {\"size\": 22}\n",
    "mpl.rc(\"font\", **font)\n",
    "\n",
    "seed = 8005\n",
    "\n",
    "np.random.seed(seed)\n",
    "rs = RandomState(MT19937(SeedSequence(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rep(df, feature):\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    color = iter(plt.cm.Accent(np.linspace(0, 1, 7)))\n",
    "\n",
    "    for i in range(1, 8):\n",
    "    \n",
    "        sns.kdeplot(df.loc[train_df[\"Cover_Type\"] == i, feature], label=f\"Cover_Type = {i}\", color=next(color))\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(f\"Repartition of {feature} among Cover_Type\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_scatter(df, feat1, feat2):\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "    color = iter(plt.cm.Accent(np.linspace(0, 1, 7)))\n",
    "\n",
    "    for i in range(1, 8):\n",
    "    \n",
    "        plt.scatter(\n",
    "            train_df.loc[train_df[\"Cover_Type\"] == i, feat1],\n",
    "            train_df.loc[train_df[\"Cover_Type\"] == i, feat2],\n",
    "            color=next(color), s=100, label=f\"Cover_Type = 1{i}\"\n",
    "        )\n",
    "\n",
    "    plt.xlabel(feat1)\n",
    "    plt.ylabel(feat2)\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read files\n",
    "test_df = pd.read_csv(\"data/covtype.csv\", index_col=[\"Id\"])\n",
    "\n",
    "training_ids = []\n",
    "\n",
    "with open(\"data/training_ids.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    training_ids = f.read().split(\",\")\n",
    "    training_ids = [int(x) for x in training_ids]\n",
    "\n",
    "train_df = test_df.iloc[training_ids, :].copy()\n",
    "\n",
    "# Eliminate useless variables\n",
    "if \"Soil_Type15\" in train_df.columns:\n",
    "    train_df.drop(columns=[\"Soil_Type15\"], inplace=True)\n",
    "    test_df.drop(columns=[\"Soil_Type15\"], inplace=True)\n",
    "    \n",
    "# Binary variables and target\n",
    "wild_var = [f\"Wilderness_Area{i}\" for i in range(1, 5)]\n",
    "soil_var = [f\"Soil_Type{i}\" for i in range(1, 41) if i != 15]\n",
    "label_var = [\"Cover_Type\"]\n",
    "\n",
    "# Separate discrete and continuous variables\n",
    "all_var = train_df.columns\n",
    "disc_var = wild_var + soil_var + label_var\n",
    "cont_var = [x for x in all_var if x not in disc_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering allows to show features that are similar to each other for future interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = train_df.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "hc.dendrogram(\n",
    "    hc.linkage(hc.distance.squareform(1-corr), method=\"average\"), \n",
    "    labels=train_df.columns, orientation=\"left\", leaf_font_size=14\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = np.around(stats.spearmanr(train_df).correlation, 2)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "hc.dendrogram(\n",
    "    hc.linkage(hc.distance.squareform(1-corr), method=\"average\"), \n",
    "    labels=train_df.columns, orientation=\"left\", leaf_font_size=14\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, missing values do not appear as NaN or inf values, but rather as limit values set by the writers of the document. Let's see with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(train_df, \"Hillshade_3pm\", \"Hillshade_Noon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_h3pm = ExtraTreesRegressor(\n",
    "    n_estimators=238, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "    max_features=\"auto\", max_leaf_nodes=None, min_impurity_decrease=5.76e-8,\n",
    "    bootstrap=False, ccp_alpha=3.64e-6, random_state=seed, n_jobs=-1, verbose=0\n",
    ")\n",
    "\n",
    "h3pm_var = \"Hillshade_3pm\"\n",
    "train_h3pm_pos = train_df.index[train_df[h3pm_var] != 0].tolist()\n",
    "train_h3pm_zeros = train_df.index[train_df[h3pm_var] == 0].tolist()\n",
    "test_h3pm_zeros = test_df.index[test_df[h3pm_var] == 0].tolist()\n",
    "\n",
    "etr_h3pm.fit(train_df.drop(columns=[h3pm_var]).loc[train_h3pm_pos, :],\n",
    "             train_df.loc[train_h3pm_pos, h3pm_var])\n",
    "\n",
    "train_df.loc[train_h3pm_zeros, h3pm_var] = \\\n",
    "    etr_h3pm.predict(train_df.drop(columns=[h3pm_var]).loc[train_h3pm_zeros, :])\n",
    "test_df.loc[test_h3pm_zeros, h3pm_var] = \\\n",
    "    etr_h3pm.predict(test_df.drop(columns=[h3pm_var]).loc[test_h3pm_zeros, :])\n",
    "\n",
    "plot_scatter(train_df, \"Hillshade_3pm\", \"Hillshade_Noon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge-domain features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, try with some combination or transformations: root, log, square, ratios, statistics, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ratio of distances to hydrology\n",
    "train_df[\"Ratio_Distance_To_Hydrology\"] = train_df[\"Vertical_Distance_To_Hydrology\"]/train_df[\"Horizontal_Distance_To_Hydrology\"]\n",
    "\n",
    "# Add Log of distance to hydrology\n",
    "train_df[\"Horizontal_Distance_To_Hydrology_Log\"] = np.log(1+train_df[\"Horizontal_Distance_To_Hydrology\"])\n",
    "\n",
    "# Add Log of distance to fire points\n",
    "train_df[\"Horizontal_Distance_To_Roadways_Log\"] = np.log(1+train_df[\"Horizontal_Distance_To_Roadways\"])\n",
    "\n",
    "# Add Max of known values\n",
    "train_df[\"Max\"] = train_df.max(axis=1)\n",
    "\n",
    "# Add Std of known values\n",
    "train_df[\"Std\"] = train_df.std(axis=1)\n",
    "\n",
    "# There might be missing values for the ratio (0 horizontal distance)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train_df[[\"Ratio_Distance_To_Hydrology\"]] = imp.fit_transform(train_df[[\"Ratio_Distance_To_Hydrology\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Ratio_Distance_To_Hydrology\")\n",
    "plot_rep(train_df, \"Horizontal_Distance_To_Hydrology_Log\")\n",
    "plot_rep(train_df, \"Horizontal_Distance_To_Roadways_Log\")\n",
    "plot_rep(train_df, \"Max\")\n",
    "plot_rep(train_df, \"Std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[cont_var].hist(figsize=(16, 12), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only some cover types have negative Vertical distance to hydrology, let's plot more information about this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature does not seem to help us learn a lot of information, we will try to define a new feature around its positivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Vertical_Distance_To_Hydrology_Sign\"] = (train_df[\"Vertical_Distance_To_Hydrology\"] > 0).astype(int)\n",
    "\n",
    "plot_rep(train_df, \"Vertical_Distance_To_Hydrology\")\n",
    "plot_rep(train_df, \"Vertical_Distance_To_Hydrology_Sign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating this feature, we help discriminating some of the cover types.\n",
    "\n",
    "Take a look at the aspect: values are among 0 to 360. We could create two features out of this: shift Aspect to -180:180 and its sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Shifted_Aspect\"] = train_df[\"Aspect\"] - 180\n",
    "train_df[\"Shifted_Aspect_Sign\"] = (train_df[\"Shifted_Aspect\"] > 0).astype(int)\n",
    "\n",
    "plot_rep(train_df, \"Aspect\")\n",
    "plot_rep(train_df, \"Shifted_Aspect_Sign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition of the signs are slightly different from cover types, but we might not learn as much information from this feature as with the sign of the vertical distance to hydrology.\n",
    "\n",
    "Regarding distance to hydrology, we can also compute its total distance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Distance_To_Hydrology\"] = (train_df[\"Horizontal_Distance_To_Hydrology\"].pow(2) + train_df[\"Vertical_Distance_To_Hydrology\"].pow(2)).pow(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Horizontal_Distance_To_Hydrology\")\n",
    "plot_rep(train_df, \"Vertical_Distance_To_Hydrology\")\n",
    "plot_rep(train_df, \"Distance_To_Hydrology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hillshade and angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total distance to hydrology is very similar to horizontal distance to hydrology, this might not help that much...\n",
    "\n",
    "Now, we will look into Hillshades features, which have small correlation with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hillshades = [\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\"]\n",
    "\n",
    "train_df[hillshades].hist(figsize=(16, 12), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Angle_To_Hydrology\"] = np.arctan(\n",
    "    train_df[\"Vertical_Distance_To_Hydrology\"]/train_df[\"Horizontal_Distance_To_Hydrology\"]\n",
    ")\n",
    "\n",
    "plot_rep(train_df, \"Angle_To_Hydrology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Mean_Hillshade\"] = train_df[hillshades].sum(axis=1)/3\n",
    "train_df[\"Aspect Hillshade_3pm\"] = train_df[\"Aspect\"] * train_df[\"Hillshade_3pm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Mean_Hillshade\")\n",
    "plot_rep(train_df, \"Aspect Hillshade_3pm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifted distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important features is that distances are related. Let's see with an example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(\n",
    "    train_df[\"Elevation\"], train_df[\"Horizontal_Distance_To_Hydrology\"],\n",
    "    c=train_df.Cover_Type.values/7, s=100, cmap=plt.cm.Accent\n",
    ")\n",
    "plt.xlabel(\"Elevation\")\n",
    "plt.ylabel(\"Horizontal_Distance_To_Hydrology\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(\n",
    "    train_df[\"Elevation\"]-0.2*train_df[\"Horizontal_Distance_To_Hydrology\"],\n",
    "    train_df[\"Horizontal_Distance_To_Hydrology\"],\n",
    "    c=train_df.Cover_Type.values/7, s=100, cmap=plt.cm.Accent\n",
    ")\n",
    "plt.xlabel(\"Elevation\")\n",
    "plt.ylabel(\"Horizontal_Distance_To_Hydrology\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(train_df, \"Elevation\", \"Vertical_Distance_To_Hydrology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[\"Elevation_Shifted_Vertical_Distance_To_Hydrology\"] = train_df[\"Elevation\"]-train_df[\"Vertical_Distance_To_Hydrology\"]\n",
    "\n",
    "plot_scatter(train_df, \"Elevation_Shifted_Vertical_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "\n",
    "plt.scatter(\n",
    "    train_df[\"Elevation\"]-0.02*train_df[\"Horizontal_Distance_To_Roadways\"],\n",
    "    train_df[\"Horizontal_Distance_To_Roadways\"],\n",
    "    c=train_df.Cover_Type.values/7, s=100, cmap=plt.cm.Accent\n",
    ")\n",
    "plt.xlabel(\"Elevation\")\n",
    "plt.ylabel(\"Horizontal_Distance_To_Hydrology\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can try to compute features that will help decision trees (boundaries!): plateaus, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_df[\"Elevation\"], bins=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [0, 1, 2]\n",
    "cut_points = [1850, 2575, 3100, 3850]\n",
    "train_df[\"Elevation_Plateau\"] = pd.cut(train_df[\"Elevation\"], cut_points, labels=[0, 1, 2]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Elevation_Plateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we might look at additions and substractions of some categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Soil_Type12_32\"] = train_df[\"Soil_Type32\"] + train_df[\"Soil_Type12\"]\n",
    "train_df[\"Soil_Type23_22_32_33\"] = \\\n",
    "    train_df[\"Soil_Type23\"] + train_df[\"Soil_Type22\"] + train_df[\"Soil_Type32\"] + train_df[\"Soil_Type33\"]\n",
    "train_df[\"Wilderness_Area1_plus_Soil_Type29\"] = train_df[\"Wilderness_Area1\"] + train_df[\"Soil_Type29\"]\n",
    "train_df[\"Wilderness_Area4_plus_Soil_Type3\"] = train_df[\"Wilderness_Area4\"] + train_df[\"Soil_Type3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Soil_Type12_32\")\n",
    "plot_rep(train_df, \"Soil_Type23_22_32_33\")\n",
    "plot_rep(train_df, \"Wilderness_Area1_plus_Soil_Type29\")\n",
    "plot_rep(train_df, \"Wilderness_Area4_plus_Soil_Type3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description of the data set, we can observe that there exist groups of soil types: families & stonyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary features\n",
    "soil_var = [f\"Soil_Type{i}\" for i in range(1, 41) if i != 15]\n",
    "wild_var = [f\"Wilderness_Area{i}\" for i in range(1, 5)]\n",
    "\n",
    "# Add the variables on training data\n",
    "s = train_df[wild_var].idxmax(axis=1).str[15:].astype(int) - 1\n",
    "train_df[\"Wilderness_Area\"] = s\n",
    "\n",
    "s = train_df[soil_var].idxmax(axis=1).str[9:].astype(int) - 1\n",
    "train_df[\"Soil_Type\"] = s\n",
    "\n",
    "# Stony/Rubly/Neither type of soil\n",
    "stony_soil_types = [1, 2, 6, 9, 12, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40]\n",
    "rubly_soil_types = [3, 4, 5, 10, 11, 13]\n",
    "other_soil_types = [7, 8, 14, 15, 16, 17, 19, 20, 21, 22]\n",
    "\n",
    "stony_dict = {i: 1 if i in stony_soil_types else 0 for i in range(1, 41)}\n",
    "rubly_dict = {i: 1 if i in rubly_soil_types else 0 for i in range(1, 41)}\n",
    "other_dict = {i: 1 if i in other_soil_types else 0 for i in range(1, 41)}\n",
    "\n",
    "train_df[\"Stony_Soil_Type\"] = train_df[\"Soil_Type\"].map(stony_dict)\n",
    "train_df[\"Rubly_Soil_Type\"] = train_df[\"Soil_Type\"].map(rubly_dict)\n",
    "train_df[\"Other_Soil_Type\"] = train_df[\"Soil_Type\"].map(other_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Stony_Soil_Type\")\n",
    "plot_rep(train_df, \"Rubly_Soil_Type\")\n",
    "plot_rep(train_df, \"Other_Soil_Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary features\n",
    "soil_var = [f\"Soil_Type{i}\" for i in range(1, 41) if i != 15]\n",
    "wild_var = [f\"Wilderness_Area{i}\" for i in range(1, 5)]\n",
    "\n",
    "# Add the variables on training data\n",
    "s = train_df[soil_var].idxmax(axis=1).str[9:].astype(int)\n",
    "\n",
    "# Families (only if more than one soil types are in)\n",
    "ratake = [2, 4]\n",
    "vanet = [2, 5, 6]\n",
    "catamount = [10, 11, 13, 26, 31, 32, 33]\n",
    "leighan = [21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 38]\n",
    "bullwark = [10, 11]\n",
    "como = [29, 30]\n",
    "moran = [38, 39, 40]\n",
    "other = [3, 14, 15, 16, 19, 20, 34, 35, 37]\n",
    "\n",
    "ratake_dict = {i: 1 if i in ratake else 0 for i in range(1, 41)}\n",
    "vanet_dict = {i: 1 if i in vanet else 0 for i in range(1, 41)}\n",
    "catamount_dict = {i: 1 if i in catamount else 0 for i in range(1, 41)}\n",
    "leighan_dict = {i: 1 if i in leighan else 0 for i in range(1, 41)}\n",
    "bullwark_dict = {i: 1 if i in bullwark else 0 for i in range(1, 41)}\n",
    "como_dict = {i: 1 if i in como else 0 for i in range(1, 41)}\n",
    "moran_dict = {i: 1 if i in moran else 0 for i in range(1, 41)}\n",
    "other_dict = {i: 1 if i in other else 0 for i in range(1, 41)}\n",
    "\n",
    "train_df[\"Ratake_Family_Soil_Type\"] = s.map(ratake_dict)\n",
    "train_df[\"Vanet_Family_Soil_Type\"] = s.map(vanet_dict)\n",
    "train_df[\"Catamount_Family_Soil_Type\"] = train_df[\"Soil_Type\"].map(catamount_dict)\n",
    "train_df[\"Leighan_Family_Soil_Type\"] = train_df[\"Soil_Type\"].map(leighan_dict)\n",
    "train_df[\"Bullwark_Family_Soil_Type\"] = train_df[\"Soil_Type\"].map(bullwark_dict)\n",
    "train_df[\"Como_Family_Soil_Type\"] = train_df[\"Soil_Type\"].map(como_dict)\n",
    "train_df[\"Moran_Family_Soil_Type\"] = train_df[\"Soil_Type\"].map(moran_dict)\n",
    "train_df[\"Other_Family_Soil_Type\"] = s.map(other_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rep(train_df, \"Bullwark_Family_Soil_Type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
