<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.engine.models.base API documentation</title>
<meta name="description" content="Initialize, fit and predict wrapper for general models." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.engine.models.base</code></h1>
</header>
<section id="section-intro">
<p>Initialize, fit and predict wrapper for general models.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Initialize, fit and predict wrapper for general models.&#34;&#34;&#34;


from typing import Any, Dict, List, Union

import warnings

from numpy import ndarray
from pandas import DataFrame

from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.multiclass import OneVsRestClassifier

from imblearn.pipeline import Pipeline
from imblearn.under_sampling import ClusterCentroids
from imblearn.over_sampling import SMOTE


warnings.filterwarnings(&#34;ignore&#34;)


class BaseEstimator():
    &#34;&#34;&#34;A wrapper for machine learning models.&#34;&#34;&#34;

    def __init__(self, model_name: str, params: Dict[str, Any]):
        &#34;&#34;&#34;The constructor of the class.

        Parameters
        ----------
        model_name : str
            The name of model following project usage. See README.md for more information.

        params : Dict[str, Any]
            A dictionary of parameters for chosen **model_name**. It contains all parameters to
            initialize and fit the model.
        &#34;&#34;&#34;
        self.model_name = model_name

        # Model parameters
        self.model_params = params

        # Instantiate model
        self.model: Any

        # Label prediction
        if model_name == &#34;rfc&#34;:
            self.model = RandomForestClassifier(**self.model_params)
        elif model_name == &#34;etc&#34;:
            self.model = ExtraTreesClassifier(**self.model_params)
        elif self.model_name == &#34;ova&#34;:
            self.model = OneVsRestClassifier(ExtraTreesClassifier(**self.model_params), n_jobs=-1)
        elif model_name == &#34;xgboost&#34;:
            self.model = XGBClassifier(**self.model_params)
        elif model_name == &#34;lightgbm&#34;:
            self.model = LGBMClassifier(**self.model_params)
        elif model_name == &#34;catboost&#34;:
            self.model = CatBoostClassifier(**self.model_params)
        elif model_name == &#34;logreg&#34;:
            self.model = LogisticRegression(**self.model_params)
        elif self.model_name == &#34;stacking&#34;:
            final_est = LogisticRegression(
                solver=&#34;newton-cg&#34;, multi_class=&#34;auto&#34;,
                random_state=self.model_params[&#34;random_state&#34;]
            )
            self.model = StackingClassifier(
                create_est(self.model_params),
                final_estimator=final_est, cv=5, n_jobs=-1, passthrough=True
            )
        elif self.model_name == &#34;resampling&#34;:
            self.model = create_resampling_pipeline(self.model_params)
        else:
            raise ValueError(&#34;{} is not implemented. Check available models.&#34;.format(model_name))

    def fit(self, x_train: Union[ndarray, DataFrame], y_train: Union[ndarray, DataFrame]):
        &#34;&#34;&#34;Wrapper of fit method.

        Parameters
        ----------
        x_train : Union[ndarray, DataFrame]
            Training features.

        y_train : Union[ndarray, DataFrame]
            Training labels.
        &#34;&#34;&#34;
        self.model.fit(x_train, y_train)

    def predict(self, x_eval: Union[ndarray, DataFrame]) -&gt; Union[ndarray, DataFrame]:
        &#34;&#34;&#34;Wrapper of predict method.

        Parameters
        ----------
        x_eval : Union[ndarray, DataFrame]
            Evaluation features.

        Returns
        -------
        y_pred : Union[ndarray, DataFrame]
            Predicted labels on evaluation set.
        &#34;&#34;&#34;
        y_pred = self.model.predict(x_eval)

        return y_pred

    def predict_proba(self, x_eval: Union[ndarray, DataFrame]) -&gt; Union[ndarray, DataFrame]:
        &#34;&#34;&#34;Wrapper of predict_proba method.

        Parameters
        ----------
        x_eval : Union[ndarray, DataFrame]
            Evaluation features.

        Returns
        -------
        y_pred_probs : Union[ndarray, DataFrame]
            Predicted probabilities on evaluation set.
        &#34;&#34;&#34;
        y_pred_probs = self.model.predict_proba(x_eval)

        return y_pred_probs


def create_est(params: Dict[str, Any]) -&gt; List[BaseEstimator]:
    &#34;&#34;&#34;Build up estimators for stacking.

    Parameters
    ----------
    params : dict of {str: any}
        A dictionary of parameters for stacking. It contains all parameters to initialize and fit
        the model.

    Returns
    -------
    est : list of `BaseEstimator`
        The complete sequence of estimators for stacking.
    &#34;&#34;&#34;
    random_state = params[&#34;random_state&#34;]

    # For now, manually estimated parameters
    etc = ExtraTreesClassifier(n_estimators=267, criterion=&#34;gini&#34;, max_depth=None,
                               min_samples_split=3, min_samples_leaf=1, max_features=&#34;auto&#34;,
                               max_leaf_nodes=None, min_impurity_decrease=8.08e-9, bootstrap=False,
                               ccp_alpha=3.11e-7, random_state=random_state, n_jobs=-1)
    rfc = RandomForestClassifier(n_estimators=156, criterion=&#34;entropy&#34;, min_samples_split=2,
                                 min_samples_leaf=1, max_features=&#34;auto&#34;, bootstrap=True,
                                 ccp_alpha=1.26e-7,  max_samples=None, random_state=random_state,
                                 n_jobs=-1)
    lgbm = LGBMClassifier(n_estimators=177, num_leaves=73, min_split_gain=1.22e-5,
                          min_child_weight=3.82e-5, min_child_samples=12, subsample=0.90,
                          subsample_freq=2, reg_alpha=1.14e-6, reg_lambda=5.37e-5,
                          random_state=random_state, n_jobs=-1)
    # xgb = XGBClassifier(n_estimators=250, use_label_encoder=False, random_state=random_state,
    #                     gamma=5.64e-2, subsample=0.78, colsample_bytree=0.94,
    #                     colsample_bylevel=0.85, colsample_bynode=0.76, max_delta_step=0.64,
    #                     reg_alpha=1.46e-7, reg_lambda=1.39e-5, grow_policy=&#34;depthwise&#34;)

    est = [(&#34;rfc&#34;, rfc), (&#34;lgbm&#34;, lgbm), (&#34;extra&#34;, etc)]

    return est


def create_resampling_pipeline(params: Dict[str, Any]) -&gt; Pipeline:
    &#34;&#34;&#34;Build up estimators for stacking.

    Parameters
    ----------
    params : Dict[str, Any]
        A dictionary of parameters for the feed-forward network. It contains all parameters to
        initialize and fit the model.

    Returns
    -------
    pipeline : Pipeline
        A complete *scikit-learn* `Pipeline` for resampling before fitting a model.
    &#34;&#34;&#34;
    seed = params[&#34;random_state&#34;]

    # Prepare the undersampling operation
    if &#34;clust_1&#34; not in params:
        error_msg = &#34;Building a Pipeline requires a repartition for Undersampling.&#34;
        raise ValueError(error_msg)

    clust_dict = {i: params[f&#34;clust_{i + 1}&#34;] for i in range(7)}

    clust = ClusterCentroids(
        sampling_strategy=clust_dict, random_state=seed, estimator=KMeans(random_state=seed)
    )

    # Prepare the oversampling operation
    if &#34;smote_1&#34; not in params:
        error_msg = &#34;Building a Pipeline requires a repartition for Oversampling.&#34;
        raise ValueError(error_msg)

    smote_dict = {i: params[f&#34;smote_{i + 1}&#34;] for i in range(7)}

    smote = SMOTE(sampling_strategy=smote_dict, random_state=seed, n_jobs=-1)

    # Prepare the model
    sampling_params = [
        f&#34;clust_{i + 1}&#34; for i in range(7)
    ] + [
        f&#34;smote_{i + 1}&#34; for i in range(7)
    ]
    model_params = {k: v for k, v in params.items() if k not in sampling_params}
    model = ExtraTreesClassifier(**model_params)

    # Build the Pipeline
    pipeline = Pipeline([(&#34;undersampling&#34;, clust), (&#34;oversampling&#34;, smote), (&#34;model&#34;, model)])

    return pipeline</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.engine.models.base.create_est"><code class="name flex">
<span>def <span class="ident">create_est</span></span>(<span>params: Dict[str, Any]) ‑> List[<a title="src.engine.models.base.BaseEstimator" href="#src.engine.models.base.BaseEstimator">BaseEstimator</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Build up estimators for stacking.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code> of <code>{str: any}</code></dt>
<dd>A dictionary of parameters for stacking. It contains all parameters to initialize and fit
the model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>est</code></strong> :&ensp;<code>list</code> of <code><a title="src.engine.models.base.BaseEstimator" href="#src.engine.models.base.BaseEstimator">BaseEstimator</a></code></dt>
<dd>The complete sequence of estimators for stacking.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_est(params: Dict[str, Any]) -&gt; List[BaseEstimator]:
    &#34;&#34;&#34;Build up estimators for stacking.

    Parameters
    ----------
    params : dict of {str: any}
        A dictionary of parameters for stacking. It contains all parameters to initialize and fit
        the model.

    Returns
    -------
    est : list of `BaseEstimator`
        The complete sequence of estimators for stacking.
    &#34;&#34;&#34;
    random_state = params[&#34;random_state&#34;]

    # For now, manually estimated parameters
    etc = ExtraTreesClassifier(n_estimators=267, criterion=&#34;gini&#34;, max_depth=None,
                               min_samples_split=3, min_samples_leaf=1, max_features=&#34;auto&#34;,
                               max_leaf_nodes=None, min_impurity_decrease=8.08e-9, bootstrap=False,
                               ccp_alpha=3.11e-7, random_state=random_state, n_jobs=-1)
    rfc = RandomForestClassifier(n_estimators=156, criterion=&#34;entropy&#34;, min_samples_split=2,
                                 min_samples_leaf=1, max_features=&#34;auto&#34;, bootstrap=True,
                                 ccp_alpha=1.26e-7,  max_samples=None, random_state=random_state,
                                 n_jobs=-1)
    lgbm = LGBMClassifier(n_estimators=177, num_leaves=73, min_split_gain=1.22e-5,
                          min_child_weight=3.82e-5, min_child_samples=12, subsample=0.90,
                          subsample_freq=2, reg_alpha=1.14e-6, reg_lambda=5.37e-5,
                          random_state=random_state, n_jobs=-1)
    # xgb = XGBClassifier(n_estimators=250, use_label_encoder=False, random_state=random_state,
    #                     gamma=5.64e-2, subsample=0.78, colsample_bytree=0.94,
    #                     colsample_bylevel=0.85, colsample_bynode=0.76, max_delta_step=0.64,
    #                     reg_alpha=1.46e-7, reg_lambda=1.39e-5, grow_policy=&#34;depthwise&#34;)

    est = [(&#34;rfc&#34;, rfc), (&#34;lgbm&#34;, lgbm), (&#34;extra&#34;, etc)]

    return est</code></pre>
</details>
</dd>
<dt id="src.engine.models.base.create_resampling_pipeline"><code class="name flex">
<span>def <span class="ident">create_resampling_pipeline</span></span>(<span>params: Dict[str, Any]) ‑> imblearn.pipeline.Pipeline</span>
</code></dt>
<dd>
<div class="desc"><p>Build up estimators for stacking.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>Dict[str, Any]</code></dt>
<dd>A dictionary of parameters for the feed-forward network. It contains all parameters to
initialize and fit the model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pipeline</code></strong> :&ensp;<code>Pipeline</code></dt>
<dd>A complete <em>scikit-learn</em> <code>Pipeline</code> for resampling before fitting a model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_resampling_pipeline(params: Dict[str, Any]) -&gt; Pipeline:
    &#34;&#34;&#34;Build up estimators for stacking.

    Parameters
    ----------
    params : Dict[str, Any]
        A dictionary of parameters for the feed-forward network. It contains all parameters to
        initialize and fit the model.

    Returns
    -------
    pipeline : Pipeline
        A complete *scikit-learn* `Pipeline` for resampling before fitting a model.
    &#34;&#34;&#34;
    seed = params[&#34;random_state&#34;]

    # Prepare the undersampling operation
    if &#34;clust_1&#34; not in params:
        error_msg = &#34;Building a Pipeline requires a repartition for Undersampling.&#34;
        raise ValueError(error_msg)

    clust_dict = {i: params[f&#34;clust_{i + 1}&#34;] for i in range(7)}

    clust = ClusterCentroids(
        sampling_strategy=clust_dict, random_state=seed, estimator=KMeans(random_state=seed)
    )

    # Prepare the oversampling operation
    if &#34;smote_1&#34; not in params:
        error_msg = &#34;Building a Pipeline requires a repartition for Oversampling.&#34;
        raise ValueError(error_msg)

    smote_dict = {i: params[f&#34;smote_{i + 1}&#34;] for i in range(7)}

    smote = SMOTE(sampling_strategy=smote_dict, random_state=seed, n_jobs=-1)

    # Prepare the model
    sampling_params = [
        f&#34;clust_{i + 1}&#34; for i in range(7)
    ] + [
        f&#34;smote_{i + 1}&#34; for i in range(7)
    ]
    model_params = {k: v for k, v in params.items() if k not in sampling_params}
    model = ExtraTreesClassifier(**model_params)

    # Build the Pipeline
    pipeline = Pipeline([(&#34;undersampling&#34;, clust), (&#34;oversampling&#34;, smote), (&#34;model&#34;, model)])

    return pipeline</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="src.engine.models.base.BaseEstimator"><code class="flex name class">
<span>class <span class="ident">BaseEstimator</span></span>
<span>(</span><span>model_name: str, params: Dict[str, Any])</span>
</code></dt>
<dd>
<div class="desc"><p>A wrapper for machine learning models.</p>
<p>The constructor of the class.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of model following project usage. See README.md for more information.</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>Dict[str, Any]</code></dt>
<dd>A dictionary of parameters for chosen <strong>model_name</strong>. It contains all parameters to
initialize and fit the model.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseEstimator():
    &#34;&#34;&#34;A wrapper for machine learning models.&#34;&#34;&#34;

    def __init__(self, model_name: str, params: Dict[str, Any]):
        &#34;&#34;&#34;The constructor of the class.

        Parameters
        ----------
        model_name : str
            The name of model following project usage. See README.md for more information.

        params : Dict[str, Any]
            A dictionary of parameters for chosen **model_name**. It contains all parameters to
            initialize and fit the model.
        &#34;&#34;&#34;
        self.model_name = model_name

        # Model parameters
        self.model_params = params

        # Instantiate model
        self.model: Any

        # Label prediction
        if model_name == &#34;rfc&#34;:
            self.model = RandomForestClassifier(**self.model_params)
        elif model_name == &#34;etc&#34;:
            self.model = ExtraTreesClassifier(**self.model_params)
        elif self.model_name == &#34;ova&#34;:
            self.model = OneVsRestClassifier(ExtraTreesClassifier(**self.model_params), n_jobs=-1)
        elif model_name == &#34;xgboost&#34;:
            self.model = XGBClassifier(**self.model_params)
        elif model_name == &#34;lightgbm&#34;:
            self.model = LGBMClassifier(**self.model_params)
        elif model_name == &#34;catboost&#34;:
            self.model = CatBoostClassifier(**self.model_params)
        elif model_name == &#34;logreg&#34;:
            self.model = LogisticRegression(**self.model_params)
        elif self.model_name == &#34;stacking&#34;:
            final_est = LogisticRegression(
                solver=&#34;newton-cg&#34;, multi_class=&#34;auto&#34;,
                random_state=self.model_params[&#34;random_state&#34;]
            )
            self.model = StackingClassifier(
                create_est(self.model_params),
                final_estimator=final_est, cv=5, n_jobs=-1, passthrough=True
            )
        elif self.model_name == &#34;resampling&#34;:
            self.model = create_resampling_pipeline(self.model_params)
        else:
            raise ValueError(&#34;{} is not implemented. Check available models.&#34;.format(model_name))

    def fit(self, x_train: Union[ndarray, DataFrame], y_train: Union[ndarray, DataFrame]):
        &#34;&#34;&#34;Wrapper of fit method.

        Parameters
        ----------
        x_train : Union[ndarray, DataFrame]
            Training features.

        y_train : Union[ndarray, DataFrame]
            Training labels.
        &#34;&#34;&#34;
        self.model.fit(x_train, y_train)

    def predict(self, x_eval: Union[ndarray, DataFrame]) -&gt; Union[ndarray, DataFrame]:
        &#34;&#34;&#34;Wrapper of predict method.

        Parameters
        ----------
        x_eval : Union[ndarray, DataFrame]
            Evaluation features.

        Returns
        -------
        y_pred : Union[ndarray, DataFrame]
            Predicted labels on evaluation set.
        &#34;&#34;&#34;
        y_pred = self.model.predict(x_eval)

        return y_pred

    def predict_proba(self, x_eval: Union[ndarray, DataFrame]) -&gt; Union[ndarray, DataFrame]:
        &#34;&#34;&#34;Wrapper of predict_proba method.

        Parameters
        ----------
        x_eval : Union[ndarray, DataFrame]
            Evaluation features.

        Returns
        -------
        y_pred_probs : Union[ndarray, DataFrame]
            Predicted probabilities on evaluation set.
        &#34;&#34;&#34;
        y_pred_probs = self.model.predict_proba(x_eval)

        return y_pred_probs</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="src.engine.models.base.BaseEstimator.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, x_train: Union[numpy.ndarray, pandas.core.frame.DataFrame], y_train: Union[numpy.ndarray, pandas.core.frame.DataFrame])</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper of fit method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_train</code></strong> :&ensp;<code>Union[ndarray, DataFrame]</code></dt>
<dd>Training features.</dd>
<dt><strong><code>y_train</code></strong> :&ensp;<code>Union[ndarray, DataFrame]</code></dt>
<dd>Training labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, x_train: Union[ndarray, DataFrame], y_train: Union[ndarray, DataFrame]):
    &#34;&#34;&#34;Wrapper of fit method.

    Parameters
    ----------
    x_train : Union[ndarray, DataFrame]
        Training features.

    y_train : Union[ndarray, DataFrame]
        Training labels.
    &#34;&#34;&#34;
    self.model.fit(x_train, y_train)</code></pre>
</details>
</dd>
<dt id="src.engine.models.base.BaseEstimator.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, x_eval: Union[numpy.ndarray, pandas.core.frame.DataFrame]) ‑> Union[numpy.ndarray, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper of predict method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_eval</code></strong> :&ensp;<code>Union[ndarray, DataFrame]</code></dt>
<dd>Evaluation features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>Union[ndarray, DataFrame]</code></dt>
<dd>Predicted labels on evaluation set.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, x_eval: Union[ndarray, DataFrame]) -&gt; Union[ndarray, DataFrame]:
    &#34;&#34;&#34;Wrapper of predict method.

    Parameters
    ----------
    x_eval : Union[ndarray, DataFrame]
        Evaluation features.

    Returns
    -------
    y_pred : Union[ndarray, DataFrame]
        Predicted labels on evaluation set.
    &#34;&#34;&#34;
    y_pred = self.model.predict(x_eval)

    return y_pred</code></pre>
</details>
</dd>
<dt id="src.engine.models.base.BaseEstimator.predict_proba"><code class="name flex">
<span>def <span class="ident">predict_proba</span></span>(<span>self, x_eval: Union[numpy.ndarray, pandas.core.frame.DataFrame]) ‑> Union[numpy.ndarray, pandas.core.frame.DataFrame]</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper of predict_proba method.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x_eval</code></strong> :&ensp;<code>Union[ndarray, DataFrame]</code></dt>
<dd>Evaluation features.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y_pred_probs</code></strong> :&ensp;<code>Union[ndarray, DataFrame]</code></dt>
<dd>Predicted probabilities on evaluation set.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_proba(self, x_eval: Union[ndarray, DataFrame]) -&gt; Union[ndarray, DataFrame]:
    &#34;&#34;&#34;Wrapper of predict_proba method.

    Parameters
    ----------
    x_eval : Union[ndarray, DataFrame]
        Evaluation features.

    Returns
    -------
    y_pred_probs : Union[ndarray, DataFrame]
        Predicted probabilities on evaluation set.
    &#34;&#34;&#34;
    y_pred_probs = self.model.predict_proba(x_eval)

    return y_pred_probs</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.engine.models" href="index.html">src.engine.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.engine.models.base.create_est" href="#src.engine.models.base.create_est">create_est</a></code></li>
<li><code><a title="src.engine.models.base.create_resampling_pipeline" href="#src.engine.models.base.create_resampling_pipeline">create_resampling_pipeline</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="src.engine.models.base.BaseEstimator" href="#src.engine.models.base.BaseEstimator">BaseEstimator</a></code></h4>
<ul class="">
<li><code><a title="src.engine.models.base.BaseEstimator.fit" href="#src.engine.models.base.BaseEstimator.fit">fit</a></code></li>
<li><code><a title="src.engine.models.base.BaseEstimator.predict" href="#src.engine.models.base.BaseEstimator.predict">predict</a></code></li>
<li><code><a title="src.engine.models.base.BaseEstimator.predict_proba" href="#src.engine.models.base.BaseEstimator.predict_proba">predict_proba</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>